{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2366b2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab libraries imported!\n",
      "Content filtering lab, version 0.1\n"
     ]
    }
   ],
   "source": [
    "from lab import __version__\n",
    "from math import exp, log\n",
    "\n",
    "print('Content filtering lab, version', __version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76939895",
   "metadata": {},
   "source": [
    "# Ethical Moderation Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f77599c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Content Moderation is a subtopic within Computer Science ethics that has gained traction since the rise of popular social media platforms. Successful platforms such as Twitter, Reddit, and Quora have bred a space where everyone is allowed to voice their opinions on any topic they please.\n",
    "\n",
    "Today, we will explore content moderation in a Computer Science perspective, and the delicate issues that arise from too much or too little moderation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ede49f",
   "metadata": {},
   "source": [
    "## Lab Background\n",
    "Sport-It is a popular social media platform which is known for its variety of communities, all of which relate to a specific sport. For example, there is a Sport-It community for the NBA, NFL, NHL, and many more. \n",
    "\n",
    "The moderators at Sport-It have decided that they want to create an environment where users only post about sports, and not controversial topics that may be harmful or too political. Today, you will be helping the moderation team by creating an algorithm that will __flag all posts not directly related to sports__.\n",
    "\n",
    "Through this lab, you will be tasked to __create an accurate machine learning algorithm__, while also questioning your own biases that may appear as you go through the lab. You will also be challenged to __think about many different edge cases__. For example, do you believe that a post harshly criticizing Colin Kapernick should be deemed as a valid post on Sport-It? *__And is there a right or wrong answer?__*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12db16c",
   "metadata": {},
   "source": [
    "# 1: Automated Content Moderation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cae0598",
   "metadata": {},
   "source": [
    "## The Naive Bayes Algorithm\n",
    "Let’s take a moment to discuss the algorithm we are going to use to properly calculate our likelihood probabilities for valid and invalid posts on Sport-It. We will be using the Naive Bayes Classifiers algorithm.\n",
    "### What does the Algorithm do?\n",
    "The Naive Bayes algorithm is a classification technique that classifies an object to a label based on prior probabilities and feature probabilities. In today’s lab, our Naive Bayes Algorithm will assign valid or invalid labels to posts, depending on the probability that the words in the post would appear in either the valid or invalid label.\n",
    "\n",
    "There are __two types of probabilities__ to look out for; the __prior probability__, and the __feature probability__. Let’s go over what each one means, and how to calculate them.\n",
    "\n",
    "__Prior Probability__, in this case, is the __probability that the post is a valid/invalid post__. Mathematically, it would look like this: <br>\n",
    "$${P}(Label = \"on topic\") = \\frac{{k} + count(on topic posts)}{2{k} + count(posts)}\\$$\n",
    "\n",
    "__Feature Probability__, in this case, is the __probability that a specific word appears in a on-topic/off-topic label__. Mathematically, it would look like this: <br>\n",
    "$${P}(Word = \"election\" | Label = \"off topic\") = \\frac{{k} + count(off topic \"election\" posts)}{2{k} + count(off topic posts)}\\$$\n",
    "\n",
    "You may have noticed a constant k appearing in the formulas above. We don’t want to run into a situation where our feature probability is 0. Adding a constant k in the numerator and denominator fixes this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b990a",
   "metadata": {},
   "source": [
    "## Using the Training Data\n",
    "We must use training data to “train” our model. We will use sample data from past posts from Sport-It, alongside pre-existing labels, to train our data. Simply put, each post will be given a label “on-topic” or “off-topic”.\n",
    "\n",
    "__Let’s start by importing any needed libraries:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040110e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import data_tools, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad500d",
   "metadata": {},
   "source": [
    "A training dataset is already provided. Each datapoint contains __text (the post title)__, and a label __y/n (whether the post is on-topic or off-topic)__. Here is an example:\n",
    "<blockquote>y: Musgrove throws first no-hitter in Padres history.</blockquote>\n",
    "Here, the post about Musgrove is considered on-topic, as it fully pertains to a sport.\n",
    "\n",
    "Let’s start by parsing through our data and assigning the parsed data to variable *training_data*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd717b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data_tools.parse_data('./data/politics.csv', './data/espn.txt', limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e4327c",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Now that we parsed our data, we should be able to easily display our data. Using some display helper methods, we can display our training data. \n",
    "\n",
    "As you look through the dataset, ask yourself: __Do you agree with the labels provided? What would you change?__ Take a moment to discuss with your group. Remember, most edge cases have no right or wrong answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70431971",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "display.display_labelled_data(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8ccb5",
   "metadata": {},
   "source": [
    "Notice that in the code below, each datapoint in the list passed into the extend function has a label __“y/n”. Your group should assign these labels. Discuss with your group, and decide a label for each datapoint.__ Remember, there is no right or wrong answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aee2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Assign each title in each datapoint a label \"y\" or \"n\".\n",
    "# Discuss within your group what you think the labels should be, and why.\n",
    "training_data.extend([\n",
    "    ('y/n', 'Deshaun Watson Admits Encounters with Masseuses, Always Consensual'),\n",
    "    ('y/n', 'Bruce Jenner is actually getting the Arthur Ashe Courage Award?'),\n",
    "    ('y/n', 'The real Tim Tebow: anti gay, anti choice, and a very unexceptional QB who owes a great deal to a teammate who is very good at kicking long fieldgoals when Tim cant get near the red zone.'),\n",
    "    ('y/n', 'TIL All NFL players have to do their physicals completely nude and are often nude for over an hour and a half. Many players have fears they were videotaped.'),\n",
    "    ('y/n', 'Broncos Brandon Marshall kneels during national anthem, follows Colin Kaepernick’s path'),\n",
    "    ('y/n', 'Megan Rapinoe says ‘not many, if any’ US womens soccer player’s would attend White House'),\n",
    "    ('y/n', 'With the upcoming Thursday night NFL game, remember that this presents a simplified view of an entire culture, caricatures facial features based on race, depicts an outdated/inaccurate style of headdress, paints them as warmongering aggressors and overly glamorizes the violent side of their history.')\n",
    "])\n",
    "\n",
    "display.display_labelled_data(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f61245",
   "metadata": {},
   "source": [
    "## Calculating Probabilities Using The Training Data\n",
    "Now that we parsed our data, we can now utilize it to our advantage. We will be calculating the prior probability of each label (on-topic and off-topic), and every feature probability for every word that appears in each group of posts. \n",
    "\n",
    "Recall that the prior probability is simply the probability of a certain label appearing in the training data. As a reminder, the equation looks like this:\n",
    "\n",
    "\n",
    "\n",
    "Let’s go ahead and look at the prior_probability function. __Keep in mind that ${k} = 1$.__ We have provided a helper class with methods to deal with the actual calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d792f7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "training_data_statistics = data_tools.DataStats(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_probabilities(label):\n",
    "    \"\"\"\n",
    "    Function input: label\n",
    "    Global/implicit input: training_data_statistics (DataStats object)\n",
    "    Output: P(Label=label)\n",
    "    \"\"\"\n",
    "    k = 1\n",
    "    num_invalid = len(training_data_statistics.invalid_posts)\n",
    "    num_valid = len(training_data_statistics.valid_posts)\n",
    "    num_total = training_data_statistics.num_posts\n",
    "    if label == 'y':\n",
    "        return (k + num_valid) / (2*k + num_total)\n",
    "    elif label == 'n':\n",
    "        return (k + num_invalid) / (2*k + num_total)\n",
    "    else:\n",
    "        raise KeyError('Unsupported label: {}'.format(label))\n",
    "print(prior_probabilities('n'))\n",
    "print(prior_probabilities('y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f50e153",
   "metadata": {},
   "source": [
    "Use the _prior_probabilities_ function to assign the prior probabilities to on-topic posts and off_topic posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e25181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO MIGHT NOT BE NEEDED\n",
    "prior_probability_ontopic = \n",
    "prior_probability_offtopic ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd6a0f5",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "We currently have the prior probabilities of both the on-topic and off-topic posts. In order to properly label posts on Sport-It as on-topic or off-topic, we also need to calculate the feature probabilities. That is, __the probability of each word appearing in each group of posts; on-topic and off-topic.__\n",
    "\n",
    "Let’s use the _word_given_label_probability_ function, that will go through each word in each post in each label, and calculate the feature probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee2f7f9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def word_given_label_probability(word, label):\n",
    "    \"\"\"\n",
    "    Function input: label\n",
    "    Global/implicit input: training_data_statistics (DataStats object)\n",
    "    Output: P(word | Label=label)\n",
    "    \"\"\"\n",
    "    if label == 'y':\n",
    "        return training_data_statistics.valid_counter[word] / training_data_statistics.total_invalid_words\n",
    "    elif label == 'n':\n",
    "        return training_data_statistics.invalid_counter[word] / training_data_statistics.total_invalid_words\n",
    "    else:\n",
    "        raise KeyError('Unsupported label: {}'.format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04ba731",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Code where they test the probability of the post being valid and the probability of the post being invalid\n",
    "Returns a tuple: (p_valid, p_invalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd323b8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def submission_probabilities(submission):\n",
    "    \"\"\"\n",
    "    Function input: submission post\n",
    "    Output: the predicted label\n",
    "    \"\"\"\n",
    "    # TODO: Using past functions and helper methods, find the likelihood of the post being on-topic and off-topic\n",
    "    likelihood_scores = (0.0, 0.0)\n",
    "    \n",
    "    \n",
    "    if likelihood_scores[0] > likelihood_scores[1]:\n",
    "        return 'y'\n",
    "    return 'n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a11c9",
   "metadata": {},
   "source": [
    "## Predicting Labels for Posts\n",
    "Time to see if our algorithm and model work! We now have the prior probabilities, as well as all the feature probabilities. We can correctly predict what label a post should have. For example if we were given the following post:\n",
    "<blockquote>The game last night was absolutely terrible!</blockquote>\n",
    "\n",
    "We should be able to __determine if this post is good or bad by the likelihood score of the on-topic label and the off-topic label__:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d1d497",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Code that returns the maximum of the probability of being valid and invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0e3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa47f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_validity(submission, threshold = 0):\n",
    "    \"\"\"\n",
    "    Input: A particular submission (title of a post)\n",
    "    Threshold: a threshold for tuning to mark for manual review\n",
    "    \"\"\"\n",
    "    # TODO: Is this log calculation problematic?\n",
    "    word_arr = data_tools.preprocess_submission(submission)\n",
    "    sum_log_word_given_valid = 0\n",
    "    sum_log_word_given_invalid = 0\n",
    "    for word in word_arr:\n",
    "        word_given_y = word_given_label_probability(word, 'y')\n",
    "        word_given_n = word_given_label_probability(word, 'n')\n",
    "        if word_given_y > 0:\n",
    "            sum_log_word_given_valid += log(word_given_y)\n",
    "        if word_given_n > 0:\n",
    "            sum_log_word_given_invalid += log(word_given_n)\n",
    "    log_ratio = log(prior_probabilities('y')) - log(prior_probabilities('n')) + sum_log_word_given_valid - sum_log_word_given_invalid\n",
    "    # TODO: Maybe assert threshhold is positive for this to work\n",
    "    if log_ratio < -1 * threshold:\n",
    "        return 'n'\n",
    "    elif log_ratio > -1 * threshold:\n",
    "        return 'y'\n",
    "    else:\n",
    "        # TODO: Maybe this isn't the symbol you want?\n",
    "        return '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733bb80",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "(UNOFFICIAL) Code that compiles all of the students' functions into a single model object generator thing\n",
    "It should also process the actual dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2558139b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Code that returns the array of tuples(label, title) based on the probabilities that we found before\n",
    "Input: testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab.data_tools import parse_unlabeled_reddit_feed, parse_unlabeled_espn\n",
    "espn_data = parse_unlabeled_espn('./data/test/espn.txt', limit=100)\n",
    "politics_data = parse_unlabeled_reddit_feed('./data/test/politics.txt', limit=100)\n",
    "\n",
    "testing_data = espn_data + politics_data\n",
    "solution = [('y', e) for e in espn_data] + [('n', p) for p in politics_data]\n",
    "\n",
    "def filter_posts(posts):\n",
    "    \"\"\"\n",
    "    Input: array of posts to filter WITHOUT labels (see output of parse_unlabeled_espn/reddit_feed)\n",
    "    Output: array of posts as tuples (label, post title), see output of parse_data\n",
    "    \"\"\"\n",
    "    # your code here!\n",
    "    result = []\n",
    "    for submission in testing_data:\n",
    "        validity = post_validity(submission)\n",
    "        result.append((validity, submission))\n",
    "\n",
    "    return result\n",
    "filtering_result = filter_posts(testing_data)\n",
    "display.display_labelled_data(filtering_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422a1827",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "Code block that returns the percentage of labels they predicted correctly\n",
    "This should *just work*, e.g. it should already be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08304e69",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate percent correctness - could just do by calculating len(verify_algorithm(test_result, solution)) / len(solution)\n",
    "def verify_algorithm(test_result, solution):\n",
    "    \"\"\"\n",
    "    Input: result of the test labelling, and the solution labelling. They should both be arrays of tuples (see output of parse_data for info)\n",
    "    Output: Entries in test_result that did not appear in solution -- also known as wrong entries\n",
    "    \"\"\"\n",
    "    return list(set(test_result) - set(solution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3724c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "mislabelled = verify_algorithm(filtering_result, solution)\n",
    "# TODO: Alter number of test cases (there are a lot of mistakes so far, I think)\n",
    "score = (1 - (len(mislabelled) / len(solution)))\n",
    "print('Your accuracy is:', 100*score,'%')\n",
    "display.display_labelled_data(mislabelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75910086",
   "metadata": {},
   "source": [
    "Look at the percentage you got when you ran the code block above. Were you expecting this score? Modify your past code, and see how the percentage changes. Try to get the best possible percentage. __Remember, incorrect moderation has real consequences for Sport-It.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ca793",
   "metadata": {},
   "source": [
    "# 2: The Effects of a Bag-Of-Words Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab4426d",
   "metadata": {},
   "source": [
    "## Bag of Words Algorithms\n",
    "The algorithm we have implemented is a __bag-of-words algorithm__. Notice that our algorithm only accounts for the __*presence*__ of words. It __does not account for any order__ or structure the post may have. Simply put, we consider each post as a random collection, or bag, of words, rather than a structure of words. There are some major downsides to just considering the amount of times a word appears in a certain label, which we will explore soon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e306a13",
   "metadata": {},
   "source": [
    "## Involuntary Censorship\n",
    "As you get the chance to predict labels for posts in the testing data, you should have begun to realize that all off-topic posts generally have a common theme in their text. Most of them may contain words such as “politics”, “kneeling”, “religion”, and more. However, __there may be some cases where our algorithm misinterpret some posts as off-topic, when in actuality, many would agree that it should be considered on-topic__. Let’s take a look at one common example:\n",
    "<blockquote>Colin Kaepernick Signs a 6 Year Contract</blockquote>\n",
    "\n",
    "This post has no underlying political tones. It is simply stating a fact about Colin Kapaernick. However, using our naive algorithm, __we might accidentally remove this post__. This is because the probability of the words “Colin Kaepernick” will show up in the off-topic group much more than the on-topic group. __Within your group, discuss how a Bag-of-words algorithm may create involuntary censorship, and who it could affect__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a8c0e7",
   "metadata": {},
   "source": [
    "# 3: The Use of Human Content Moderation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a6501",
   "metadata": {},
   "source": [
    "## Introducing Human Content Moderation\n",
    "You may have been wondering why we chose to create a simple machine learning algorithm to moderate content at all. Why wouldn’t Sport-It create a simple flag function that flags any post that contains offensive or political words, and have employees or volunteers sift through the rest of the posts?\n",
    "\n",
    "There have been many studies that prove that there are extremely traumatic effects on humans whose job is to filter through hundreds and thousands of posts daily, that contain topics much heavier than political views on a sports platform. It is important that as we extend the idea of automated content moderation from Sport-It to real platforms used by millions of users daily, we understand that __the need for human content moderators must be kept at an absolute minimum_.\n",
    "\n",
    "__As you go through this next exercise, keep in mind the balance between accurate flagging, and effects of human content moderation on a large scale__.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e35b6d",
   "metadata": {},
   "source": [
    "## Handling a Threshold\n",
    "As mentioned before, we want to keep the amount of content reviewed by people as low as possible, without ruining the validity of our algorithm. Therefore, we will only request human moderation on posts that the algorithm is on the fence about. In other words, if the difference between the on-topic and off-topic probability is extremely low, only then will we request further review.\n",
    "Take a look at the code below. There is a number that represents the threshold. This threshold decides whether or not the post should be sent in a pile for further review. Play around with the threshold, and look at the resulting count of posts in the pile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b084a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: IMPLEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daded7c",
   "metadata": {},
   "source": [
    "As you increase or decrease the threshold, __keep in mind the implication of your action__. By changing the threshold, you are effectively choosing what this reviewer will see. __Within your group, discuss at what point does the accuracy of the algorithm start to plateau and the psychological toll on the reviewer rise? How do you properly balance between these two concepts?__ Remember that human moderation should be used only when extremely necessary, and should be kept at a low whenever possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38daa34a",
   "metadata": {},
   "source": [
    "# Discussion Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ef9ca",
   "metadata": {},
   "source": [
    "It’s important to understand the real world implications our algorithm can have on an individual's freedom of speech. What may seem like a trivial content moderation task can single-handedly take down companies if users feel like their content is too heavily monitored.<br>\n",
    " - __How would an inaccurate algorithm affect Sport-It?__\n",
    " - __How did you and your group handle edge cases in the data set? Did you agree with the labels assigned to the edge cases?__\n",
    " - __This was a simple algorithm that just handled the frequencies of words, and not necessarily the order of words. Do some quick research and think of another algorithm that might be more effective.__\n",
    " - __What platforms that you use today may benefit from a content moderation algorithm?__\n",
    " - __What problems may we run into if there is too much moderation on a platform? Consider the concepts of diversity of opinions and “bubbles.”__\n",
    " - __Who decides what constitutes off topic or political conversations?__"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
